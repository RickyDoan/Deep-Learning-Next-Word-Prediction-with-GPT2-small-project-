{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-07T17:25:18.231677Z",
     "start_time": "2025-01-07T17:20:59.678206Z"
    }
   },
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cdbbcce1176e48beb95a8af0445bdf47"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa00706fc4d046d1a4dda91fe6b0a5bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e16af6c799694ed4b700964d3033ab14"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f16c20fb5dba48fb9c17abda0f7c3ff9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ed817b35c61a4285bf0ee00d3a227718"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92552a78c6fb4b9ca61fadef1968ce68"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4fbf1416b7c24c2eb7c82305108e99b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/transformers/pytorch_utils.py:335: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello, I'm a language model, and my project will get better with time, but I think there are a lot more things that can help you\"},\n",
       " {'generated_text': \"Hello, I'm a language model, not a language model, so if I don't have a problem, I can fix it by creating new words\"},\n",
       " {'generated_text': \"Hello, I'm a language model, and I'm trying to learn some stuff. I'll try to do some basic programming and just learn better ways\"},\n",
       " {'generated_text': \"Hello, I'm a language model, but I don't believe in grammar. This will work for every language model. You can define it very quickly\"},\n",
       " {'generated_text': 'Hello, I\\'m a language model, a model of how things should be, and then we look at different things as well.\" I\\'d like to'}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T17:25:58.991479Z",
     "start_time": "2025-01-07T17:25:56.538779Z"
    }
   },
   "cell_type": "code",
   "source": "generator(\"How much money do you have?\", max_length=30, num_return_sequences=5)",
   "id": "b2fc6b280d673bb5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"How much money do you have?\\n\\nThe total number of credits you can earn as a trader for each of the six categories you're in may\"},\n",
       " {'generated_text': 'How much money do you have? Well, I think it should be divided. You know, for this, we need to pay them, so our'},\n",
       " {'generated_text': \"How much money do you have?\\n\\nI started building my own studio a few months ago and since then I've built most digital and Blu-\"},\n",
       " {'generated_text': 'How much money do you have? $20,000-$50,000?$100,000-$200,000\\n\\n\"I think not'},\n",
       " {'generated_text': 'How much money do you have? How much money do you have to earn?\" It\\'s hard to quantify exactly how much one could spend for $33'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T18:08:56.686072Z",
     "start_time": "2025-01-07T18:08:56.667544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "def next_word_prediction(prompt):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "    output = model(**inputs)\n",
    "    logits = output.logits\n",
    "    last_token_logits = logits[:, -1, :]\n",
    "    max_indices = torch.argmax(last_token_logits)\n",
    "    return tokenizer.decode(max_indices)\n"
   ],
   "id": "f471692636674164",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T18:09:13.488572Z",
     "start_time": "2025-01-07T18:09:11.358981Z"
    }
   },
   "cell_type": "code",
   "source": "next_word_prediction(\"I would like to ask you a question about the weather in\")",
   "id": "beef89c2dc49ec82",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T18:09:56.181305Z",
     "start_time": "2025-01-07T18:09:55.149153Z"
    }
   },
   "cell_type": "code",
   "source": "next_word_prediction(\"Apollo 11 landed on the Moon on\")",
   "id": "1d47e9a7960f08e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' July'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T18:10:58.173976Z",
     "start_time": "2025-01-07T18:10:57.036819Z"
    }
   },
   "cell_type": "code",
   "source": "next_word_prediction(\"The sun is\")",
   "id": "a323b55076aeb82",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' shining'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T18:11:44.480808Z",
     "start_time": "2025-01-07T18:11:43.435543Z"
    }
   },
   "cell_type": "code",
   "source": "next_word_prediction(\"I hope you doing\")",
   "id": "46ed7f6607434d0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' well'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T17:56:13.943765Z",
     "start_time": "2025-01-07T17:56:08.663112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "text = \"I would like to ask you a question about the weather in\"\n",
    "generator(text, max_length=50, num_return_sequences=5, truncation=True)"
   ],
   "id": "43102bb4edfd3745",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'I would like to ask you a question about the weather in the region of Houston right now.\\n\\nI know this city is a little rainy. I can tell you there is not much I can do about that. So I would suggest people just'},\n",
       " {'generated_text': \"I would like to ask you a question about the weather in the UK, we're all here for an afternoon break and I've been told that there's not that many weather stations along the way. We're seeing weather in other parts of the UK\"},\n",
       " {'generated_text': 'I would like to ask you a question about the weather in Colorado and Arizona, how you manage your temperature, humidity, and humidity as well as weather extremes. Please send me an email, but I will not send you pictures. I will even add'},\n",
       " {'generated_text': \"I would like to ask you a question about the weather in your hometown. We believe in bringing more rain than cold weather. It's just about a matter of weather. Anytime you want to have a good and calm place in the state, do\"},\n",
       " {'generated_text': 'I would like to ask you a question about the weather in San Francisco. Can you tell me about it in the same way you did as a young kid, or how does it affect you as a man?\\n\\nThe first time I saw the'}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
